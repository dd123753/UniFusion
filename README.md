# UniFusion
# Benchmark è¯„ä¼°å¹³å°ä½¿ç”¨è¯´æ˜

## å¹³å°åŠŸèƒ½

æä¾›ä¸¤ä¸ªæ ¸å¿ƒè¯„ä¼°ç•Œé¢ï¼š

1. **å•æ–¹æ³•æ€§èƒ½æµ‹è¯•ç•Œé¢**  
   - æµ‹è¯•æŒ‡å®šæ–¹æ³•åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„æ€§èƒ½æŒ‡æ ‡
   - è¾“å‡ºç»“æœåŒ…æ‹¬ï¼šFLOPS/å‚æ•°é‡/å¹³å‡è¿è¡Œæ—¶é—´
   - è‡ªåŠ¨ä¿å­˜èåˆç»“æœåˆ°`results/æ–¹æ³•å/`

2. **å¤šæ–¹æ³•å¯¹æ¯”ç•Œé¢**  
   - å¯¹åŒä¸€åœºæ™¯ä¸‹å„æ–¹æ³•çš„èåˆæŒ‡æ ‡ç»“æœè¿›è¡Œç»¼åˆæ¯”å¯¹
   - ä»…é€šç”¨æ–¹æ³•ä¼šè¿›è¡Œè·¨åœºæ™¯è¯„ä¼°
   - ä¸“ç”¨æ–¹æ³•åªåœ¨é¢„è®¾åœºæ™¯ä¸‹æ˜¾ç¤º


## å¹³å°é€‚é…ä»£ç 
æœ¬å¹³å°ä»…æä¾›ï¼š
- ğŸ“Œ äºŒæ¬¡å¼€å‘çš„**æŒ‡æ ‡ç»Ÿè®¡æ¨¡å—**
- ğŸ“Œ é€‚é…æœ¬å¹³å°çš„**æ¥å£å¯¹æ¥ä»£ç **

## å®Œæ•´ä»£ç è·å–
1. åŸå§‹æ–¹æ³•è¯·è®¿é—®å„é¡¹ç›®åŸä»“åº“
2. å®Œæ•´é€‚é…ç‰ˆæœ¬ï¼ˆå«ä¾èµ–è°ƒæ•´ï¼‰è¯·è”ç³»æœ¬å¹³å°ä½œè€…è·å–



  
## âš ï¸ æ€§èƒ½æ³¨æ„äº‹é¡¹

**ç”±äºç½‘ç»œé€šä¿¡å’Œç¡¬ä»¶æ€§èƒ½é™åˆ¶ï¼Œä½¿ç”¨æ—¶å¯èƒ½å‡ºç°ï¼š**
- åŠ è½½ç•Œé¢æ˜¾ç¤ºçŸ­æš‚å¡é¡¿
- æŒ‡æ ‡æ–‡ä»¶ç”Ÿæˆå»¶è¿Ÿï¼ˆçº¦10-30ç§’ä¸ç­‰ï¼‰
- å¤šæ–¹æ³•å¯¹æ¯”æ—¶çš„åŠ è½½ç­‰å¾…


# åŸºå‡†æµ‹è¯•æ–¹æ³•æºç å¼•ç”¨è¯´æ˜

## å¼€æºæ–¹æ³•å¼•ç”¨
æ‰€æœ‰åŸºå‡†æ–¹æ³•çš„åŸå§‹ä»£ç å‡æ¥è‡ªä»¥ä¸‹GitHubä»“åº“ï¼š

## IVIF MethodsğŸ“š Source Code References

| Method Name       | Original Repository                               | Paper Citation                                                                                                                                                                                                                           |
|-------------------|---------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| RFN-Nest          |[https://github.com/hli1221/imagefusion-rfn-nest]  | Li et al., Rfn-nest: An end-to-end residual fusion network for infrared and visible images. Information Fusion,73:72â€“86, 2021.                                                                                                           |
| UNFusion          | [https://github.com/Zhishe-Wang/UNFusion]         | Wang et al.,Unfusion: A unified multi-scale densely connected network forinfrared and visible image fusion. IEEE Transactions on Circuits and Systems for Video Technology, 32(6):3360â€“3374, 2021.                                       |
| SuperFusion       | [https://github.com/Linfeng-Tang/SuperFusion]     | Tang et al., Superfusion: A versatile image registration and fusion network with semantic awareness. IEEE/CAA Journal of Automatica Sinica, 9(12):2121â€“2137, 2022.                                                                       |
| ReCoNet           | [https://github.com/dlut-dimt/ReCoNet]            | Huang et al., Reconet: Recurrent correction network for fast and efficient multi-modality image fusion. In European conference on computer Vision, pages 539â€“555. Springer, 2022.                                                        |
| SeAFusion         | [https://github.com/Linfeng-Tang/SeAFusion]       | Tang et al., Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network. Information Fusion, 82:28â€“42, 2022.                                                              |
| PIAFusion         | [https://github.com/Linfeng-Tang/PIAFusion]       | Tang et al., Piafusion: A progressive infrared and visible image fusion network based on illumination aware. Information Fusion, 83:79â€“92, 2022.                                                                                         |
| DATFuse           | [https://github.com/tthinking/DATFuse]            | Tang et al., Datfuse: Infrared and visible image fusion via dual attention transformer. IEEE Transactions on Circuits and Systems for Video Technology, 33(7):3159â€“3172, 2023.                                                           |
| PSFusion          | [https://github.com/Linfeng-Tang/PSFusion]        | Tang et al., Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity. Information Fusion, 99:101870, 2023. |
| MetaFusion        | [https://github.com/wdzhao123/MetaFusion]         | Zhao et al., Metafusion: Infrared and visible image fusion via meta-feature embedding from object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13955â€“13965, 2023.              |
| SDCFusion         | [https://github.com/XiaoW-Liu/SDCFusion]          | Liu et al., A semantic-driven coupled network for infrared and visible image fusion. Information Fusion, 108:102352, 2024                                                                                                                |
| Text-IF           | [https://github.com/XunpengYi/Text-IF]            | Yi et al., Text-if: Leveraging semantic text guidance for degradation-aware and interactive image fusion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 27026â€“27035,2024.                  | 
| PromptFusion      | [https://github.com/hey-it-s-me/PromptFusion]     | Liu et al., Promptfusion: Harmonized semantic prompt learning for infrared and visible image fusion. IEEE/CAA Journal of Automatica Sinica, 2024.                                                                                        |
| Conti-Fuse        | [https://github.com/zipper112/Conti-Fuse]         | Li et al., Conti-fuse: A novel continuous decomposition-based fusion framework for infrared and visible images. Information Fusion, 117:102839, 2025.                                                                                    |
| CrossFuse         | [https://github.com/CidanShi/CrossFuse]           | Shi et al., Crossfuse: Learning infrared and visible image fusion by cross-sensor top-k vision alignment and beyond. IEEE Transactions on Circuits and Systems for Video Technology, 2025.                                               |

## MIF MethodğŸ“š Source Code References

| Method Name       | Original Repository                                 | Paper Citation       |
|-------------------|-----------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|
| BSAFusion        | [https://github.com/slrl123/BSAFusion]                   | Li et al., Bsafusion: A bidirectional stepwise feature alignment network for unaligned medical image fusion. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 4725â€“4733, 2025.  |
| GeSeNet       | [https://github.com/lok-18/GeSeNet]                   |Li et al., Gesenet: A general semantic-guided network with couple mask ensemble for medical image fusion. IEEE Transactions on Neural Networks and Learning Systems, 2023.  |
| MACTFusion          | [https://github.com/millieXie/MACTFusion]                   | Xie et al., Mactfusion: Lightweight cross transformer for adaptive multimodal medical image fusion. IEEE Journal of Biomedical and Health Informatics, 2024.  |
| MRSCFusion        | [https://github.com/millieXie/MRSCFusion]                  | Xie et al.,  Mrscfusion: Joint residual swin transformer and multiscale cnn for unsupervised multimodal medical image fusion. IEEE Transactions on Instrumentation and Measurement, 72:1â€“17, 2023. |
 |MsgFusion         | [https://github.com/22385wjy/MsgFusion]                   | Wen et al., Msgfusion: Medical semantic guided two-branch network for multimodal brain image fusion. IEEE Transactions on Multimedia, 26:944â€“957, 2023.  |
 |MSRPAN          | [https://github.com/jeffsonfu/MSRPAN]                  | Fu et al.,  A multiscale residual pyramid attention network for medical image fusion. Biomedical Signal Processing and Control, 66:102488, 2021.  |
 |Zero-LMF      | [https://github.com/PanPapag/Zero-Learning-Fast-Medical-Image-Fusion]                   | Fayez Lahoud and Sabine SÃ¼sstrunk. Zero-learning fast medical image fusion. In 2019 22th international conference on information fusion (FUSION), pages 1â€“8. IEEE, 2019. |
 |MATR         | [https://github.com/tthinking/MATR]                   | Tang et al., Matr: Multimodal medical image fusion via multiscale adaptive transformer. IEEE Transactions on Image Processing, 31:5134â€“5149, 2022.  |
 |FATFusion         | [https://github.com/tthinking/FATFusion]                  | Tang et al., Fatfusion: A functionalâ€“anatomical transformer for medical image fusion. Information Processing & Management, 61(4):103687, 2024.  |

## MFIF MethodğŸ“š Source Code References

| Method Name       | Original Repository                                  | Paper Citation       |
|-------------------|------------------------------------------------------|----------------------|
| DRPL                | [https://github.com/sasky1/DRPL]                   | Li et al., Drpl: Deep regression pair learning for multi-focus image fusion. IEEE Transactions on Image Processing, 29:4816â€“4831, 2020.  |
| MCCSR-Net         | [https://github.com/yuliu316316/CCSR-Net-Fusion]                    | Zheng et al.,  Unfolding coupled convolutional sparse representation for multi-focus image fusion. Information Fusion, 118:102974, 2025. |
| MFFT          | [https://github.com/zwy0913/MFFT]                    | Zhai et al.,  Multi-focus image fusion via interactive transformer and asymmetric soft sharing. Engineering Applications of Artificial Intelligence, 133:107967, 2024. |
| ZMFF       | [https://github.com/junjun-jiang/ZMFF]                  | Hu et al.,  Zmff: Zero-shot multi-focus image fusion. Information Fusion, 92:127â€“138, 2023.                                                                                                |
| MFIF-GAN         | [https://github.com/ycwang-libra/MFIF-GAN]                    | Wang et al., Mfif-gan: A new generative adversarial network for multi-focus image fusion. Signal Processing: Image Communication, 96:116295, 2021.               |
| SESF-Fuse         | [https://github.com/Keep-Passion/SESF-Fuse]                    | Ma et al., Sesf-fuse: An unsupervised deep model for multi-focus image fusion. Neural Computing and Applications, 33(11):5793â€“5804, 2021. |
## UNIVERSAL MethodğŸ“š Source Code References

| Method Name       | Original Repository                                  | Paper Citation       |
|-------------------|------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| SwinFusion          | [https://github.com/Linfeng-Tang/SwinFusion]                    |Ma et al.,  Swinfusion: Cross-domain long-range learning for general image fusion via swin transformer. IEEE/CAA Journal of Automatica Sinica, 9(7):1200â€“1217, 2022.                                                                                          |
| DDFM          | [https://github.com/Zhaozixiang1228/MMIF-DDFM]                    | Zhao et al., Ddfm: denoising diffusion model for multi-modality image fusion. In Proceedings of the IEEE/CVF international conference on computer vision, pages 8082â€“8093, 2023                                                                       |
| CDDFuse         | [https://github.com/Zhaozixiang1228/MMIF-CDDFuse]                    | Zhao et al., Cddfuse: Correlation-driven dual-branch feature decomposition for multi-modality image fusion. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 5906â€“5916, 2023.  |
| EMMA          | [https://github.com/Zhaozixiang1228/MMIF-EMMA]                    | Zhao et al., Equivariant multi-modality image fusion. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 25912â€“25921, 2024.                                                                                       |
| TIM          | [https://github.com/LiuZhu-CV/TIMFusion]                    | Liu et al.,  A task-guided, implicitly-searched and meta-initialized deep model for image fusion. IEEE Transactions on Pattern Analysis and Machine Intelligence, 46(10):6594â€“6609, 2024.                                                           |
| MMAE        | [https://github.com/xiangxiang-wang/MMAE]                   | Wang et al.,  Mmae: A universal image fusion method via mask attention mechanism. Pattern Recognition, 158:111041, 2025.                                                                                                                                                          |
|LFDT-Fusion           | [https://github.com/BOYang-pro/LFDT-Fusion]                     | Yang et al.,  Lfdt-fusion: A latent feature-guided diffusion transformer model for general image fusion. Information Fusion, 113:102639, 2025.                                                                                                                                   |
| MMIF-INet          | [https://github.com/HeDan-11/MMIF-INet]               | He et al.,  Mmif-inet: Multimodal medical image fusion by invertible network. Information Fusion, 114:102666, 2025.  |






