# UniFusion
# Benchmark ËØÑ‰º∞Âπ≥Âè∞‰ΩøÁî®ËØ¥Êòé

## Âπ≥Âè∞ÂäüËÉΩ

Êèê‰æõ‰∏§‰∏™Ê†∏ÂøÉËØÑ‰º∞ÁïåÈù¢Ôºö

1. **ÂçïÊñπÊ≥ïÊÄßËÉΩÊµãËØïÁïåÈù¢**  
   - ÊµãËØïÊåáÂÆöÊñπÊ≥ïÂú®ÁâπÂÆöÂú∫ÊôØ‰∏ãÁöÑÊÄßËÉΩÊåáÊ†á
   - ËæìÂá∫ÁªìÊûúÂåÖÊã¨ÔºöFLOPS/ÂèÇÊï∞Èáè/Âπ≥ÂùáËøêË°åÊó∂Èó¥
   - Ëá™Âä®‰øùÂ≠òËûçÂêàÁªìÊûúÂà∞`results/ÊñπÊ≥ïÂêç/`

2. **Â§öÊñπÊ≥ïÂØπÊØîÁïåÈù¢**  
   - ÂØπÂêå‰∏ÄÂú∫ÊôØ‰∏ãÂêÑÊñπÊ≥ïÁöÑËûçÂêàÊåáÊ†áÁªìÊûúËøõË°åÁªºÂêàÊØîÂØπ
   - ‰ªÖÈÄöÁî®ÊñπÊ≥ï‰ºöËøõË°åË∑®Âú∫ÊôØËØÑ‰º∞
   - ‰∏ìÁî®ÊñπÊ≥ïÂè™Âú®È¢ÑËÆæÂú∫ÊôØ‰∏ãÊòæÁ§∫


## Âπ≥Âè∞ÈÄÇÈÖç‰ª£Á†Å
Êú¨Âπ≥Âè∞‰ªÖÊèê‰æõÔºö
- üìå ‰∫åÊ¨°ÂºÄÂèëÁöÑ**ÊåáÊ†áÁªüËÆ°Ê®°Âùó**
- üìå ÈÄÇÈÖçÊú¨Âπ≥Âè∞ÁöÑ**Êé•Âè£ÂØπÊé•‰ª£Á†Å**

## ÂÆåÊï¥‰ª£Á†ÅËé∑Âèñ
1. ÂéüÂßãÊñπÊ≥ïËØ∑ËÆøÈóÆÂêÑÈ°πÁõÆÂéü‰ªìÂ∫ì
2. ÂÆåÊï¥ÈÄÇÈÖçÁâàÊú¨ÔºàÂê´‰æùËµñË∞ÉÊï¥ÔºâËØ∑ËÅîÁ≥ªÊú¨Âπ≥Âè∞‰ΩúËÄÖËé∑Âèñ



  
## ‚ö†Ô∏è ÊÄßËÉΩÊ≥®ÊÑè‰∫ãÈ°π

**Áî±‰∫éÁΩëÁªúÈÄö‰ø°ÂíåÁ°¨‰ª∂ÊÄßËÉΩÈôêÂà∂Ôºå‰ΩøÁî®Êó∂ÂèØËÉΩÂá∫Áé∞Ôºö**
- Âä†ËΩΩÁïåÈù¢ÊòæÁ§∫Áü≠ÊöÇÂç°È°ø
- ÊåáÊ†áÊñá‰ª∂ÁîüÊàêÂª∂ËøüÔºàÁ∫¶10-30Áßí‰∏çÁ≠âÔºâ
- Â§öÊñπÊ≥ïÂØπÊØîÊó∂ÁöÑÂä†ËΩΩÁ≠âÂæÖ

> ÊºîÁ§∫GIF‰∏≠Â∑≤ÂåÖÂê´Ëøô‰∫õÊ≠£Â∏∏Áé∞Ë±°ÁöÑË°®Áé∞ÔºåËØ∑‰ª•ÂÆûÈôÖËøêË°åÊÉÖÂÜµ‰∏∫ÂáÜ


# Âü∫ÂáÜÊµãËØïÊñπÊ≥ïÊ∫êÁ†ÅÂºïÁî®ËØ¥Êòé

## ÂºÄÊ∫êÊñπÊ≥ïÂºïÁî®
ÊâÄÊúâÂü∫ÂáÜÊñπÊ≥ïÁöÑÂéüÂßã‰ª£Á†ÅÂùáÊù•Ëá™‰ª•‰∏ãGitHub‰ªìÂ∫ìÔºö

## IVIF Methodsüìö Source Code References

| Method Name       | Original Repository                               | Paper Citation                                                                                                                                                                                                                           |
|-------------------|---------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| RFN-Nest          |[https://github.com/hli1221/imagefusion-rfn-nest]  | Li et al., Rfn-nest: An end-to-end residual fusion network for infrared and visible images. Information Fusion,73:72‚Äì86, 2021.                                                                                                           |
| UNFusion          | [https://github.com/Zhishe-Wang/UNFusion]         | Wang et al.,Unfusion: A unified multi-scale densely connected network forinfrared and visible image fusion. IEEE Transactions on Circuits and Systems for Video Technology, 32(6):3360‚Äì3374, 2021.                                       |
| SuperFusion       | [https://github.com/Linfeng-Tang/SuperFusion]     | Tang et al., Superfusion: A versatile image registration and fusion network with semantic awareness. IEEE/CAA Journal of Automatica Sinica, 9(12):2121‚Äì2137, 2022.                                                                       |
| ReCoNet           | [https://github.com/dlut-dimt/ReCoNet]            | Huang et al., Reconet: Recurrent correction network for fast and efficient multi-modality image fusion. In European conference on computer Vision, pages 539‚Äì555. Springer, 2022.                                                        |
| SeAFusion         | [https://github.com/Linfeng-Tang/SeAFusion]       | Tang et al., Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network. Information Fusion, 82:28‚Äì42, 2022.                                                              |
| PIAFusion         | [https://github.com/Linfeng-Tang/PIAFusion]       | Tang et al., Piafusion: A progressive infrared and visible image fusion network based on illumination aware. Information Fusion, 83:79‚Äì92, 2022.                                                                                         |
| DATFuse           | [https://github.com/tthinking/DATFuse]            | Tang et al., Datfuse: Infrared and visible image fusion via dual attention transformer. IEEE Transactions on Circuits and Systems for Video Technology, 33(7):3159‚Äì3172, 2023.                                                           |
| PSFusion          | [https://github.com/Linfeng-Tang/PSFusion]        | Tang et al., Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity. Information Fusion, 99:101870, 2023. |
| MetaFusion        | [https://github.com/wdzhao123/MetaFusion]         | Zhao et al., Metafusion: Infrared and visible image fusion via meta-feature embedding from object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13955‚Äì13965, 2023.              |
| SDCFusion         | [https://github.com/XiaoW-Liu/SDCFusion]          | Liu et al., A semantic-driven coupled network for infrared and visible image fusion. Information Fusion, 108:102352, 2024                                                                                                                |
| Text-IF           | [https://github.com/XunpengYi/Text-IF]            | Yi et al., Text-if: Leveraging semantic text guidance for degradation-aware and interactive image fusion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 27026‚Äì27035,2024.                  | 
| PromptFusion      | [https://github.com/hey-it-s-me/PromptFusion]     | Liu et al., Promptfusion: Harmonized semantic prompt learning for infrared and visible image fusion. IEEE/CAA Journal of Automatica Sinica, 2024.                                                                                        |
| Conti-Fuse        | [https://github.com/zipper112/Conti-Fuse]         | Li et al., Conti-fuse: A novel continuous decomposition-based fusion framework for infrared and visible images. Information Fusion, 117:102839, 2025.                                                                                    |
| CrossFuse         | [https://github.com/CidanShi/CrossFuse]           | Shi et al., Crossfuse: Learning infrared and visible image fusion by cross-sensor top-k vision alignment and beyond. IEEE Transactions on Circuits and Systems for Video Technology, 2025.                                               |

## MIF Methodüìö Source Code References

| Method Name       | Original Repository                                 | Paper Citation       |
|-------------------|-----------------------------------------------------|----------------------|
| Method A          | [github.com/original/repoA](url)                    | Author et al., 2020  |
| Method B          | [github.com/original/repoB](url)                    | Author et al., 2021  |
| Method C          | [github.com/original/repoC](url)                    | Author et al., 2022  |
## MFIF Methodüìö Source Code References

| Method Name       | Original Repository                                  | Paper Citation       |
|-------------------|------------------------------------------------------|----------------------|
| Method A          | [github.com/original/repoA](url)                     | Author et al., 2020  |
| Method B          | [github.com/original/repoB](url)                     | Author et al., 2021  |
| Method C          | [github.com/original/repoC](url)                     | Author et al., 2022  |
## UNIVERSAL Methodüìö Source Code References

| Method Name       | Original Repository                                  | Paper Citation       |
|-------------------|------------------------------------------------------|----------------------|
| Method A          | [github.com/original/repoA](url)                     | Author et al., 2020  |
| Method B          | [github.com/original/repoB](url)                     | Author et al., 2021  |
| Method C          | [github.com/original/repoC](url)                     | Author et al., 2022  |





